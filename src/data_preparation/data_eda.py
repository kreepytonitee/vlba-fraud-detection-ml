# -*- coding: utf-8 -*-
"""Data EDA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HNGLdZ4_EHh4zcMfB3JNeeIVm_mzueBc

# **Cleaning and splitting the dataset**
"""

import pandas as pd
from sklearn.model_selection import train_test_split

# Let’s load the .csv file given to us
df = pd.read_csv('transactions.csv')

# Let's check for missing values in target before the split and drop them
missing_targets = df['Is Laundering'].isnull().sum()
print(f"Missing values in 'Is Laundering': {missing_targets}")
df = df.dropna(subset=['Is Laundering'])

print(f"Data shape after dropping missing target rows: {df.shape}")

# Let’s store the Target column in a variable
target_col = 'Is Laundering'

# Performing stratified split: 75% train, 25% production (Splitting it in 75-25 ratio)
train_df, prod_df = train_test_split(
    df,
    test_size=0.25,
    stratify=df[target_col],
    random_state=42
)

# This line remove's target column from production data before saving
prod_df_no_label = prod_df.drop(columns=[target_col])

# Save train data WITH LABELS
train_df.to_csv('transactions_train.csv', index=False)

# Save production data WITHOUT LABELS
prod_df_no_label.to_csv('transactions_production.csv', index=False)

# Let’s print the class distribution for confirming if the split’s done well
print("Training data class distribution:")
print(train_df[target_col].value_counts(normalize=True))

print("\nProduction data class distribution:")
print(prod_df[target_col].value_counts(normalize=True))

"""# **EDA**

1) EDA 1
"""

df = pd.read_csv('transactions_train.csv')

# Display basic information about the dataset
print("Dataset Info:")
print(df.info())

# Display the first few rows of the dataset
print("\nFirst few rows of the dataset:")
print(df.head())

# Statistics for numerical columns
print("\nDescriptive statistics for numerical columns:")
print(df.describe())

# Unique values in the target variable "is_fraud"
print("\nKnowing Unique values in 'is Laundering':")
print(df['Is Laundering'].value_counts())

# Check for missing values
print("\nAny Missing values in the dataset?")
print(df.isnull().sum())

"""EDA 2

1. Visualize the original Amount Received and Amount Paid distributions and compare with log-transformed plots.
"""

import numpy as np
import matplotlib.pyplot as plt

# Assuming df is loaded and log columns created
df['log_amount_received'] = np.log1p(df['Amount Received'])
df['log_amount_paid'] = np.log1p(df['Amount Paid'])

plt.figure(figsize=(14,10))

plt.subplot(2,2,1)
plt.hist(df['Amount Received'], bins=100)
plt.title('Amount Received (Original Scale)')
plt.xlabel('Amount Received')
plt.ylabel('Count')

plt.subplot(2,2,2)
plt.hist(df['Amount Paid'], bins=100)
plt.title('Amount Paid (Original Scale)')
plt.xlabel('Amount Paid')
plt.ylabel('Count')

plt.subplot(2,2,3)
plt.hist(df['log_amount_received'], bins=100)
plt.title('Log-transformed Amount Received')
plt.xlabel('Log(1 + Amount Received)')
plt.ylabel('Count')

plt.subplot(2,2,4)
plt.hist(df['log_amount_paid'], bins=100)
plt.title('Log-transformed Amount Paid')
plt.xlabel('Log(1 + Amount Paid)')
plt.ylabel('Count')

plt.tight_layout()
plt.show()

"""2. Time based analysis"""

df['Timestamp'] = pd.to_datetime(df['Timestamp'])
df['Year'] = df['Timestamp'].dt.year
df['Month'] = df['Timestamp'].dt.month
df['Day'] = df['Timestamp'].dt.day
df['Hour'] = df['Timestamp'].dt.hour
df['Minute'] = df['Timestamp'].dt.minute

def time_summary(df):
    print("Transaction counts by Year:")
    print(df['Year'].value_counts().sort_index())
    print("\nTransaction counts by Month:")
    print(df['Month'].value_counts().sort_index())
    print("\nTransaction counts by Day:")
    print(df['Day'].value_counts().sort_index())
    print("\nTransaction counts by Hour:")
    print(df['Hour'].value_counts().sort_index())
    print("\nTransaction counts by Minute:")
    print(df['Minute'].value_counts().sort_index())

time_summary(df)

# Filter for fraud transactions only
df_fraud = df[df['Is Laundering'] == 1]

def fraud_time_summary(df):
    print("Fraud Transaction counts by Year:")
    print(df['Year'].value_counts().sort_index())
    print("\nFraud Transaction counts by Month:")
    print(df['Month'].value_counts().sort_index())
    print("\nFraud Transaction counts by Day:")
    print(df['Day'].value_counts().sort_index())
    print("\nFraud Transaction counts by Hour:")
    print(df['Hour'].value_counts().sort_index())
    print("\nFraud Transaction counts by Minute:")
    print(df['Minute'].value_counts().sort_index())

fraud_time_summary(df_fraud)

import matplotlib.pyplot as plt
import pandas as pd

# Filtering fraud and non-fraud
df_fraud = df[df['Is Laundering'] == 1]
df_nonfraud = df[df['Is Laundering'] == 0]

# Defining full ranges for time units
all_days = range(1, df['Day'].max() + 1)
all_hours = range(0, 24)
all_minutes = range(0, 60)

# Total and Fraud counts reindexed with zeros for missing entries
total_by_day = df['Day'].value_counts().sort_index().reindex(all_days, fill_value=0)
fraud_by_day = df_fraud['Day'].value_counts().sort_index().reindex(all_days, fill_value=0)

total_by_hour = df['Hour'].value_counts().sort_index().reindex(all_hours, fill_value=0)
fraud_by_hour = df_fraud['Hour'].value_counts().sort_index().reindex(all_hours, fill_value=0)

total_by_minute = df['Minute'].value_counts().sort_index().reindex(all_minutes, fill_value=0)
fraud_by_minute = df_fraud['Minute'].value_counts().sort_index().reindex(all_minutes, fill_value=0)

# Compute fraud rates safely (avoid division by zero)
fraud_rate_day = fraud_by_day / total_by_day.replace(0, pd.NA)
fraud_rate_hour = fraud_by_hour / total_by_hour.replace(0, pd.NA)
fraud_rate_minute = fraud_by_minute / total_by_minute.replace(0, pd.NA)

# 1. Total and Fraud Transactions by Day
plt.figure(figsize=(12,6))
plt.bar(total_by_day.index - 0.2, total_by_day.values, width=0.4, label='Total Transactions')
plt.bar(fraud_by_day.index + 0.2, fraud_by_day.values, width=0.4, label='Fraud Transactions')
plt.xlabel('Day of Month')
plt.ylabel('Transaction Count')
plt.title('Transactions by Day')
plt.legend()
plt.yscale('log')
plt.show()

# 2. Fraud Rate by Day
plt.figure(figsize=(10,5))
fraud_rate_day.plot(kind='bar', color='orange')
plt.xlabel('Day of Month')
plt.ylabel('Fraud Rate')
plt.title('Fraud Rate by Day')
plt.show()

# 3. Fraud Transactions by Hour
plt.figure(figsize=(10,5))
(fraud_by_hour + 1).plot(kind='bar', color='red', logy=True)
plt.xlabel('Hour of Day')
plt.ylabel('Fraud Transaction Count (log scale)')
plt.title('Fraud Transactions by Hour')
plt.show()

# 4. Fraud Rate by Hour
plt.figure(figsize=(10,5))
fraud_rate_hour.plot(kind='bar', color='purple')
plt.xlabel('Hour of Day')
plt.ylabel('Fraud Rate')
plt.title('Fraud Rate by Hour')
plt.show()

# 5. Fraud Transactions by Minute
plt.figure(figsize=(15,5))
(fraud_by_minute + 1).plot(kind='bar', color='green', logy=True)
plt.xlabel('Minute of Hour')
plt.ylabel('Fraud Transaction Count (log scale)')
plt.title('Fraud Transactions by Minute')
plt.show()

# 6. Fraud Rate by Minute
plt.figure(figsize=(15,5))
fraud_rate_minute.plot(kind='bar', color='brown')
plt.xlabel('Minute of Hour')
plt.ylabel('Fraud Rate')
plt.title('Fraud Rate by Minute')
plt.show()

"""3. Categorical feature analysis"""

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

categorical_cols = ['Payment Format', 'From Bank', 'To Bank', 'Payment Currency', 'Receiving Currency']

for col in categorical_cols:
    print(f"Analysis for {col}\n")

    # Full distribution counts
    counts = df[col].value_counts()
    print(f"Counts by category:\n{counts}\n")

    # Full fraud rate by category
    fraud_rates = df.groupby(col)['Is Laundering'].mean().sort_values(ascending=False)
    print(f"Fraud rates by category:\n{fraud_rates}\n")

    # Visualization for top 20 categories by count
    plt.figure(figsize=(14,5))

    plt.subplot(1, 2, 1)
    top_categories = counts.index[:20]
    sns.countplot(data=df, x=col, order=top_categories)
    plt.xticks(rotation=45)
    plt.title(f'Distribution of {col} (Top 20 Categories)')

    plt.subplot(1, 2, 2)
    fraud_rates_top = fraud_rates.loc[top_categories]
    sns.barplot(x=fraud_rates_top.index, y=fraud_rates_top.values)
    plt.xticks(rotation=45)
    plt.title(f'Fraud Rate by {col} (Top 20 Categories)')
    plt.ylabel('Fraud Rate')

    plt.tight_layout()
    plt.show()

"""4. Detecting outliers"""

import matplotlib.pyplot as plt

# Boxplots to visualize outliers
plt.figure(figsize=(12,5))

plt.subplot(1,2,1)
plt.boxplot(df['Amount Received'], vert=False)
plt.title('Boxplot of Amount Received')

plt.subplot(1,2,2)
plt.boxplot(df['Amount Paid'], vert=False)
plt.title('Boxplot of Amount Paid')

plt.show()

# IQR method to identify outliers
def find_outliers_iqr(data):
    Q1 = data.quantile(0.25)
    Q3 = data.quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = data[(data < lower_bound) | (data > upper_bound)]
    return outliers

outliers_received = find_outliers_iqr(df['Amount Received'])
outliers_paid = find_outliers_iqr(df['Amount Paid'])

print(f"Number of outliers in Amount Received: {len(outliers_received)}")
print(f"Number of outliers in Amount Paid: {len(outliers_paid)}")

import matplotlib.pyplot as plt

# Flag outliers using IQR method for Amount Received
Q1_received = df['Amount Received'].quantile(0.25)
Q3_received = df['Amount Received'].quantile(0.75)
IQR_received = Q3_received - Q1_received
lower_bound_received = Q1_received - 1.5 * IQR_received
upper_bound_received = Q3_received + 1.5 * IQR_received

df['Outlier_Received'] = (df['Amount Received'] < lower_bound_received) | (df['Amount Received'] > upper_bound_received)

# Flag outliers using IQR method for Amount Paid
Q1_paid = df['Amount Paid'].quantile(0.25)
Q3_paid = df['Amount Paid'].quantile(0.75)
IQR_paid = Q3_paid - Q1_paid
lower_bound_paid = Q1_paid - 1.5 * IQR_paid
upper_bound_paid = Q3_paid + 1.5 * IQR_paid

df['Outlier_Paid'] = (df['Amount Paid'] < lower_bound_paid) | (df['Amount Paid'] > upper_bound_paid)

# Count of outliers by fraud status
outlier_received_fraud_counts = df.groupby(['Outlier_Received', 'Is Laundering']).size().unstack(fill_value=0)
outlier_paid_fraud_counts = df.groupby(['Outlier_Paid', 'Is Laundering']).size().unstack(fill_value=0)

print("Outlier in Amount Received by Fraud Status:")
print(outlier_received_fraud_counts)
print("\nOutlier in Amount Paid by Fraud Status:")
print(outlier_paid_fraud_counts)